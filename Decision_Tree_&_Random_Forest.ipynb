{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree & Random Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpfDJ3Q4Anz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb791e36-be40-4b93-b922-a71674b29359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "#import necessary modules\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import numpy as np\n",
        "from sklearn import feature_extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the data\n",
        "train_h = pd.read_csv('train_stances.csv')\n",
        "train_b = pd.read_csv('train_bodies.csv')\n",
        "test_h = pd.read_csv('competition_test_stances.csv')\n",
        "test_b = pd.read_csv('competition_test_bodies.csv')"
      ],
      "metadata": {
        "id": "jHMb4QX_BXlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to merge the headlines and articlebody datasets\n",
        "def merge(d1, d2):\n",
        "  data = pd.merge(d1, d2, how='inner', left_on=['Body ID'], right_on=['Body ID'])\n",
        "  return data"
      ],
      "metadata": {
        "id": "tBIGQO9mBZcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing specials chars, puting words in lowercase\n",
        "def clean(s):\n",
        "  return re.sub(\"[^a-zA-Z]\", \" \",str(s)).lower()\n",
        "\n",
        "_wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "# lemmatizing\n",
        "def normalize_word(w):\n",
        "  return _wnl.lemmatize(w).lower()\n",
        "\n",
        "# tokenizing\n",
        "def get_tokenized_lemmas(s):\n",
        "  return [normalize_word(t) for t in nltk.word_tokenize(s)]\n",
        "\n",
        "# removing stopwords\n",
        "def remove_stopwords(l):\n",
        "    return [w for w in l if w not in feature_extraction.text.ENGLISH_STOP_WORDS]\n",
        "\n",
        "# do all the above preprocessing and put back into sentences\n",
        "def preprocess(data, title):\n",
        "  content = []\n",
        "  content = [clean(line) for line in data[title]]\n",
        "  content = [remove_stopwords(line) for line in data[title]]\n",
        "  content = [get_tokenized_lemmas(line) for line in data[title]]\n",
        "  content = [' '.join(x) for x in content]\n",
        "  data[title] = content\n"
      ],
      "metadata": {
        "id": "tl-DPka7HRuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do all necessary preprocessing on all data we need\n",
        "preprocess(train_h, 'Headline')\n",
        "preprocess(train_b, 'articleBody')\n",
        "preprocess(test_h, 'Headline')\n",
        "preprocess(test_b, 'articleBody')\n"
      ],
      "metadata": {
        "id": "F-IZrUJFEFc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge bodies and headlines\n",
        "test_data = merge(test_h, test_b)\n",
        "train_data = merge(train_h, train_b)"
      ],
      "metadata": {
        "id": "qIObBcRclWaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of all sentences from the headlines and the bodies to use in the tf vectorizer\n",
        "sentences = []\n",
        "for line in train_data['Headline']:\n",
        "  sentences.append(line)\n",
        "for line in train_data['articleBody']:\n",
        "  sentences.append(line)"
      ],
      "metadata": {
        "id": "9vUKMv8_0GMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function vectorizes the words/sentences and also measures the similaries between headings and bodies\n",
        "# it returns data pertaining to the vectorized haedings, bodies, and their similarities\n",
        "def tf_data(df):\n",
        "    tfvectorizer = TfidfVectorizer(max_features=2000, use_idf=False).fit(sentences)\n",
        "    tfidfvectorizer = TfidfVectorizer(max_features=2000, use_idf=True).fit(sentences)\n",
        "    data = []\n",
        "    for index, row in df.iterrows():\n",
        "        head = row['Headline']\n",
        "        body = row['articleBody']\n",
        "        tf_head = tfvectorizer.transform([head]).toarray().reshape(1, -1)\n",
        "        tf_body = tfvectorizer.transform([body]).toarray().reshape(1, -1)\n",
        "        head_tfidf = tfidfvectorizer.transform([head]).toarray()\n",
        "        body_tfidf = tfidfvectorizer.transform([body]).toarray()\n",
        "        # using cosine similarity\n",
        "        tfidf_cos = cosine_similarity(head_tfidf, body_tfidf).reshape(1, -1)\n",
        "        # merging the features\n",
        "        features= np.squeeze(np.c_[tf_head, tf_body, tfidf_cos])\n",
        "        data.append(features)\n",
        "    data = np.array(data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "u8ER8s8XmanF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measure run time train\n",
        "\n",
        "# import the builtin time module\n",
        "import time\n",
        "\n",
        "# Grab Currrent Time Before Running the Code\n",
        "start = time.time()\n",
        "\n",
        "X_train = tf_data(train_data)\n",
        "\n",
        "# Grab Currrent Time After Running the Code\n",
        "end = time.time()\n",
        "\n",
        "#Subtract Start Time from The End Time\n",
        "total_time1 = end - start\n",
        "print(\"\\n\"+ str(total_time1))\n",
        "\n",
        "\n",
        "#test\n",
        "\n",
        "# Grab Currrent Time Before Running the Code\n",
        "start = time.time()\n",
        "\n",
        "X_test = tf_data(test_data)\n",
        "\n",
        "# Grab Currrent Time After Running the Code\n",
        "end = time.time()\n",
        "\n",
        "#Subtract Start Time from The End Time\n",
        "total_time2 = end - start\n",
        "print(total_time1,total_time2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFONiPUeQVUU",
        "outputId": "42ac0201-e55b-469a-d7ff-1f86545a7e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "208.88915395736694\n",
            "208.88915395736694 116.78624153137207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the stances with numerical values\n",
        "train_data.Stance.replace('unrelated', 1, True)\n",
        "train_data.Stance.replace('agree', 2, True)\n",
        "train_data.Stance.replace('disagree', 3, True)\n",
        "train_data.Stance.replace('discuss', 4, True)\n",
        "\n",
        "y_train = train_data['Stance']"
      ],
      "metadata": {
        "id": "tleuQGQIrGof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run decision tree classifier\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# import the builtin time module\n",
        "import time\n",
        "\n",
        "# Grab Currrent Time Before Running the Code\n",
        "start = time.time()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Grab Currrent Time After Running the Code\n",
        "end = time.time()\n",
        "\n",
        "#Subtract Start Time from The End Time\n",
        "total_time1 = end - start\n",
        "print(\"\\n\"+ str(total_time1))\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMw2QR67sH9T",
        "outputId": "1a345cbe-288c-4f75-a747-6ce3b8315e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "416.4039099216461\n",
            "[1 1 4 ... 1 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put the prediction results back into the stance labels\n",
        "stances = []\n",
        "for p in range(len(prediction)):\n",
        "  if prediction[p] == 1: \n",
        "    stances.append(\"unrelated\")\n",
        "  if prediction[p] == 2: \n",
        "    stances.append(\"disagree\")\n",
        "  if prediction[p] == 3: \n",
        "    stances.append(\"agree\")\n",
        "  if prediction[p] == 4: \n",
        "    stances.append(\"discuss\")"
      ],
      "metadata": {
        "id": "XgHGcK9oxWBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(real, test):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in range(len(real)):\n",
        "    if real[i] == test[i]:\n",
        "      correct += 1\n",
        "    total += 1\n",
        "  print( correct/total)"
      ],
      "metadata": {
        "id": "C_3GieiNLTHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = {}\n",
        "predictions_df = pd.DataFrame({'Stance': stances})\n",
        "\n",
        "get_accuracy(test_data['Stance'], predictions_df['Stance'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxjqnwQD3Nzz",
        "outputId": "591123d1-95ca-4def-f0f1-da7234b480fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7537874316294809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "\n",
        "    for i in range(len(gold_labels)):  \n",
        "      if gold_labels[i] == test_labels[i]:\n",
        "        if gold_labels[i] == 'unrelated':\n",
        "          score += 0.25\n",
        "        if gold_labels[i]!= 'unrelated':\n",
        "          score += 0.75\n",
        "      elif gold_labels[i] != 'unrelated':\n",
        "        if test_labels[i] in ['agrees', 'disagrees', 'discusses']:\n",
        "          score += 0.25\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "dM-l-12lV_Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get score from this model\n",
        "score_submission(test_data['Stance'], predictions_df['Stance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuTIQwVQV_xF",
        "outputId": "12b6a5db-b8ac-4829-b612-d8ed1b5122d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6065.5"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "JLiA3Q-j4HHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run Random Forest Classifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# import the builtin time module\n",
        "import time\n",
        "\n",
        "# Grab Currrent Time Before Running the Code\n",
        "start = time.time()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Grab Currrent Time After Running the Code\n",
        "end = time.time()\n",
        "\n",
        "#Subtract Start Time from The End Time\n",
        "total_time1 = end - start\n",
        "print(\"\\n\"+ str(total_time1))\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw5ohJWJ4I96",
        "outputId": "60b79210-8dd1-407e-80b0-96d451469d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "178.53488302230835\n",
            "[1 1 2 ... 1 1 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stances = []\n",
        "for p in range(len(prediction)):\n",
        "  if prediction[p] == 1: \n",
        "    stances.append(\"unrelated\")\n",
        "  if prediction[p] == 2: \n",
        "    stances.append(\"disagree\")\n",
        "  if prediction[p] == 3: \n",
        "    stances.append(\"agree\")\n",
        "  if prediction[p] == 4: \n",
        "    stances.append(\"discuss\")"
      ],
      "metadata": {
        "id": "i-7KQmUs5BPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = {}\n",
        "predictions_df = pd.DataFrame({'Stance': stances})\n",
        "\n",
        "get_accuracy(test_data['Stance'], predictions_df['Stance'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMSnT2SJ5EHc",
        "outputId": "1b56c227-7a89-44c6-fa12-94298315d26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8143076378231614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "\n",
        "    for i in range(len(gold_labels)):  \n",
        "      if gold_labels[i] == test_labels[i]:\n",
        "        if gold_labels[i] == 'unrelated':\n",
        "          score += 0.25\n",
        "        if gold_labels[i]!= 'unrelated':\n",
        "          score += 0.75\n",
        "      elif gold_labels[i] != 'unrelated':\n",
        "        if test_labels[i] in ['agrees', 'disagrees', 'discusses']:\n",
        "          score += 0.25\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "nv9KKPK9KBHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get score from this model\n",
        "score_submission(test_data['Stance'], predictions_df['Stance'])"
      ],
      "metadata": {
        "id": "RaoWGO50Lfoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('competition_test_stances_unlabeled.csv')\n",
        "df['Stance'] = predictions_df['Stance']\n",
        "df.to_csv('answer.csv')"
      ],
      "metadata": {
        "id": "UWyxS7arQEjQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}